# VisualVoice for Helping Visually Impaired Users

VisualVoice is a web application designed to help visually impaired users by allowing them to upload images and generate captions using a pre-trained model. The generated captions are then converted into speech using Google Text-to-Speech (gTTS), allowing users to hear the description of the image.

## Features
- **Image Caption Generation**: Upload an image file, and the application generates a caption describing the content of the image using the `Salesforce/blip-image-captioning-base` model.
- **Text-to-Speech Conversion**: Converts the generated caption into audio using Google Text-to-Speech (gTTS), which can be played directly on the webpage.
- **User-Friendly Web Interface**: The application is designed to be accessible, with a simple, easy-to-navigate interface that displays the uploaded image and generated caption, alongside an audio player to listen to the caption.

## Project Structure

```
VisualVoice/
│
├── app.py                     # Main Flask app
├── static/                     # Static files (uploads and audio)
│   ├── uploads/                # Folder for uploaded images
│   └── audio/                  # Folder for audio files generated by gTTS
├── templates/
│   └── index.html              # HTML file for rendering the webpage
├── requirements.txt            # Python dependencies
└── README.md                   # Project documentation
```

## Installation and Setup

Follow these steps to set up and run the **VisualVoice** application locally:

1. **Clone the repository:**

   ```bash
   git clone https://github.com/Anushka-Pote/VisualVoice.git
   cd VisualVoice
   ```

2. **Create a virtual environment:**

   ```bash
   python3 -m venv venv
   source venv/bin/activate   # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

4. **Run the Flask application:**

   ```bash
   python app.py
   ```

5. **Open your browser and navigate to:**

   ```plaintext
   http://127.0.0.1:5000/
   ```

## Dependencies

This project relies on the following libraries:

- **Flask**: Web framework used to create the application.
- **Pillow**: For image processing.
- **transformers**: Hugging Face library for loading the image captioning model.
- **gTTS**: Google Text-to-Speech library for converting text into speech.
- **Werkzeug**: Used for securing file uploads.

To install the dependencies, use:

```bash
pip install -r requirements.txt
```

## Usage

1. **Upload an Image**: 
   Upload any image file (e.g., `.jpg`, `.png`) through the web interface.

2. **Generate Caption**: 
   Once the image is uploaded, the model will generate a caption describing the content of the image.

3. **Play Caption as Audio**: 
   The generated caption will be converted to speech using Google Text-to-Speech (gTTS). An audio player will appear, allowing you to listen to the caption.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
